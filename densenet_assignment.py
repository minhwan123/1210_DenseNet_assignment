# -*- coding: utf-8 -*-
"""DenseNet_Assignment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EQpBh1fUD3Wqg4MAJBFH1zNr_JnBlYJO
"""

# Check GPU
!nvidia-smi

from google.colab import drive
drive.mount('/content/drive')

from pathlib import Path

# Dataset root in Google Drive
DATA_ROOT = Path("/content/drive/MyDrive/POC_Dataset")

# Directory to save results (model + plots)
OUTPUT_DIR = Path("/content/drive/MyDrive/DenseNet_Results")
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

print("DATA_ROOT exists:", DATA_ROOT.exists())
print("OUTPUT_DIR:", OUTPUT_DIR)

import os
from typing import Tuple, List

import numpy as np
import cv2
import matplotlib.pyplot as plt
from PIL import Image

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, models

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

class CustomPOCDataset(Dataset):
    """
    Custom dataset for POC histology images.
    Loads images from class folders and returns (image, label).
    """

    def __init__(
        self,
        data_dir: str,
        data_type: str = "Training",
        size: Tuple[int, int] = (224, 224),
        is_augment: bool = False,
        transform=None,
        target_transform=None,
    ):
        super().__init__()

        self.data_dir = data_dir
        self.data_type = data_type
        self.size = size
        self.is_augment = is_augment

        self.transform = transform
        self.target_transform = target_transform

        # Load class folder names (sorted for label consistency)
        self.class_names = sorted(
            os.listdir(os.path.join(self.data_dir, self.data_type))
        )

        # Collect image filenames + labels
        self.image_names, self.labels = self.__process_data()

    def __len__(self):
        """Return dataset size."""
        return len(self.image_names)

    def __getitem__(self, idx):
        """Return one sample (image_tensor, label_tensor)."""
        image_name = self.image_names[idx]
        label = self.labels[idx]

        class_name = self.class_names[label]
        image_path = os.path.join(
            self.data_dir, self.data_type, class_name, image_name
        )

        # Load image
        image = Image.open(image_path).convert("RGB")
        image_np = np.array(image)

        # Preprocess (resize only)
        processed = self.__preprocess_data(image_np, save=False, size=self.size)

        # Apply transforms
        if self.transform:
            image_tensor = self.transform(processed)
        else:
            image_tensor = (
                torch.from_numpy(processed).permute(2, 0, 1).float() / 255.0
            )

        # Convert label to tensor
        if self.target_transform:
            label_tensor = self.target_transform(label)
        else:
            label_tensor = torch.tensor(label).long()

        # Optional simple augmentation
        if self.is_augment:
            k = np.random.randint(0, 4)  # random rotation (0/90/180/270)
            image_tensor = torch.rot90(image_tensor, k, dims=[1, 2])
            if np.random.rand() < 0.5:   # random horizontal flip
                image_tensor = torch.flip(image_tensor, dims=[2])

        return image_tensor, label_tensor

    def __process_data(self):
        """Scan class folders and assign integer labels."""
        image_names = []
        labels = []

        for label_idx, class_name in enumerate(self.class_names):
            class_dir = os.path.join(self.data_dir, self.data_type, class_name)
            files = [
                f for f in os.listdir(class_dir)
                if f.lower().endswith((".jpg", ".jpeg", ".png"))
            ]
            image_names.extend(files)
            labels.extend([label_idx] * len(files))

        return image_names, labels

    def __preprocess_data(
        self,
        image: np.ndarray,
        save: bool = False,
        size: Tuple[int, int] = (224, 224),
    ) -> np.ndarray:
        """
        Preprocessing pipeline:
        - Convert RGB to BGR (OpenCV format)
        - Resize to target size using bicubic interpolation
        """
        img_bgr = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
        resized = cv2.resize(
            img_bgr, (size[1], size[0]), interpolation=cv2.INTER_CUBIC
        )
        resized_rgb = cv2.cvtColor(resized, cv2.COLOR_BGR2RGB)
        return resized_rgb

    @staticmethod
    def plot_grid_images(x, y, batch_size: int = 9, class_names: List[str] = None):
        """Utility to visualize batch samples in a grid."""
        rows = cols = int(batch_size ** 0.5)
        fig, axes = plt.subplots(rows, cols, figsize=(10, 10))
        axes = axes.flatten()

        for i in range(batch_size):
            img = x[i].permute(1, 2, 0).cpu().numpy()
            axes[i].imshow(img)
            if class_names:
                axes[i].set_title(f"Label: {class_names[int(y[i])]}")
            else:
                axes[i].set_title(f"Label: {int(y[i])}")
            axes[i].axis("off")

        plt.tight_layout()
        plt.show()

def get_densenet(num_classes: int, pretrained: bool = True):
    """
    Return a DenseNet-121 classifier.
    Replace the final Linear layer with 'num_classes'.
    """
    if pretrained:
        model = models.densenet121(
            weights=models.DenseNet121_Weights.IMAGENET1K_V1
        )
    else:
        model = models.densenet121(weights=None)

    in_features = model.classifier.in_features
    model.classifier = nn.Linear(in_features, num_classes)

    return model

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)

batch_size = 32
num_epochs = 20
learning_rate = 1e-4

# Transforms (ImageNet style)
train_transform = transforms.Compose([
    transforms.ToPILImage(),
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225],
    ),
])

test_transform = transforms.Compose([
    transforms.ToPILImage(),
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225],
    ),
])

# Datasets
train_dataset = CustomPOCDataset(
    data_dir=str(DATA_ROOT),
    data_type="Training",
    size=(224, 224),
    is_augment=False,
    transform=train_transform,
)

test_dataset = CustomPOCDataset(
    data_dir=str(DATA_ROOT),
    data_type="Testing",
    size=(224, 224),
    is_augment=False,
    transform=test_transform,
)

num_classes = len(train_dataset.class_names)
print("Classes:", train_dataset.class_names)
print("Train samples:", len(train_dataset))
print("Test samples:", len(test_dataset))

# Dataloaders
train_loader = DataLoader(
    train_dataset,
    batch_size=batch_size,
    shuffle=True,
    num_workers=2,
    pin_memory=True if device.type == "cuda" else False,
)

test_loader = DataLoader(
    test_dataset,
    batch_size=batch_size,
    shuffle=False,
    num_workers=2,
    pin_memory=True if device.type == "cuda" else False,
)

# Model, loss, optimizer
model = get_densenet(num_classes=num_classes, pretrained=True)
model = model.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)

best_acc = 0.0
best_model_path = OUTPUT_DIR / "best_densenet.pth"

train_losses = []
train_accs = []
test_accs = []

# -----------------------------
# Training loop
# -----------------------------
for epoch in range(1, num_epochs + 1):
    model.train()
    running_loss = 0.0
    running_correct = 0

    # ---- Train ----
    for images, labels in train_loader:
        images = images.to(device, non_blocking=True)
        labels = labels.to(device, non_blocking=True)

        optimizer.zero_grad()

        outputs = model(images)
        loss = criterion(outputs, labels)

        loss.backward()
        optimizer.step()

        running_loss += loss.item() * images.size(0)
        preds = outputs.argmax(dim=1)
        running_correct += (preds == labels).sum().item()

    epoch_loss = running_loss / len(train_dataset)
    epoch_acc = running_correct / len(train_dataset)

    # ---- Test ----
    model.eval()
    test_correct = 0
    test_total = 0

    with torch.no_grad():
        for images, labels in test_loader:
            images = images.to(device, non_blocking=True)
            labels = labels.to(device, non_blocking=True)

            outputs = model(images)
            preds = outputs.argmax(dim=1)

            test_correct += (preds == labels).sum().item()
            test_total += labels.size(0)

    test_acc = test_correct / test_total if test_total > 0 else 0.0

    train_losses.append(epoch_loss)
    train_accs.append(epoch_acc)
    test_accs.append(test_acc)

    print(
        f"[Epoch {epoch:02d}] "
        f"Train Loss: {epoch_loss:.4f} | "
        f"Train Acc: {epoch_acc:.4f} | "
        f"Test Acc: {test_acc:.4f}"
    )

    if test_acc > best_acc:
        best_acc = test_acc
        torch.save(model.state_dict(), best_model_path)
        print(f"âœ” Saved best model: {best_acc:.4f}")
        print(f"   Path: {best_model_path}")

# -----------------------------
# Plot training curves
# -----------------------------
epochs = range(1, num_epochs + 1)

plt.figure()
plt.plot(epochs, train_losses, label="Train Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.title("Training Loss")
plt.legend()
plt.savefig(OUTPUT_DIR / "loss_curve.png")
plt.show()

plt.figure()
plt.plot(epochs, train_accs, label="Train Acc")
plt.plot(epochs, test_accs, label="Test Acc")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.title("Accuracy")
plt.legend()
plt.savefig(OUTPUT_DIR / "accuracy_curve.png")
plt.show()

print("\nTraining completed.")
print(f"Best Test Accuracy: {best_acc:.4f}")
print(f"Best model saved to: {best_model_path}")

# Load best model
model.load_state_dict(torch.load(best_model_path, map_location=device))
model.eval()

all_labels = []
all_preds = []

with torch.no_grad():
    for images, labels in test_loader:
        images = images.to(device, non_blocking=True)
        labels = labels.to(device, non_blocking=True)

        outputs = model(images)
        preds = outputs.argmax(dim=1)

        all_labels.extend(labels.cpu().tolist())
        all_preds.extend(preds.cpu().tolist())

cm = confusion_matrix(all_labels, all_preds)
disp = ConfusionMatrixDisplay(
    confusion_matrix=cm,
    display_labels=train_dataset.class_names,
)

fig, ax = plt.subplots(figsize=(5, 5))
disp.plot(ax=ax, cmap="Blues", colorbar=False)
plt.title("Confusion Matrix (Test Set)")
plt.savefig(OUTPUT_DIR / "confusion_matrix.png")
plt.show()